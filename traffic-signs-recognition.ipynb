{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nfrom skimage.color import rgb2lab\nfrom skimage.transform import resize\nfrom collections import namedtuple\n%matplotlib inline\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input/trafficsigns'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\nimport tensorflow.compat.v1 as tf1\ntf1.disable_v2_behavior() \n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":31,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Preprocessing***"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# 43 different classes(traffic signs)\n# The size of the images after being resized\nn_classes = 43 \nresized_image = (32, 32)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the images, convert them to grayscale \n# resize them to a predefined shape\n# and also one-hot encode the label\n\nDataset= namedtuple('Dataset', ['X', 'y'])\ndef to_tf_format(imgs):\n    return np.stack([img[:,:, np.newaxis] for img in imgs], axis=0).astype(np.float32)\n\ndef read_dataset(rootpath, n_labels, resize_to):\n    images = []\n    labels = []\n    for c in range(n_labels):\n        full_path = rootpath + '/' + format(c, '05d') + '/'\n        for img_name in glob.glob(full_path + '*.ppm'):\n            img = plt.imread(img_name)\n            img = rgb2lab(img)[:, :, 0] \n            img = resize(img, resize_to, mode = 'reflect')\n            label = np.zeros((n_labels), dtype=np.float32)\n            label[c] = 1.0\n            images.append(img.astype(np.float32))\n            labels.append(label)\n\n            return Dataset(X = to_tf_format(images).astype(np.float32), y = np.matrix(labels).astype(np.float32))\n\n#Run the function \ndataset = read_dataset('D:/Projects/Traffic-signs/data/GTSRB/Images', n_classes, resized_image)\nprint(dataset.X.shape)\nprint(dataset.y.shape) ","execution_count":33,"outputs":[{"output_type":"stream","text":"(39209, 32, 32, 1)\n(39209, 43)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Observe the first image in our dataset\n# together with its label\nplt.imshow(dataset.X[0,:,:,:].reshape(resized_image))\nprint(dataset.y[0])","execution_count":34,"outputs":[{"output_type":"stream","text":"[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset into training data(75%) and test data(25%)\n\nfrom sklearn.model_selection import train_test_split\nidx_train, idx_test = train_test_split(range(dataset.X.shape[0]), test_size=0.25, random_state=10)\nXtrain = dataset.X[idx_train,...]\nXtest = dataset.X[idx_test,...]\nytrain = dataset.y[idx_train,...]\nytest = dataset.y[idx_test,...]\nprint(Xtrain.shape)\nprint(Xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)","execution_count":35,"outputs":[{"output_type":"stream","text":"(29406, 32, 32, 1)\n(9803, 32, 32, 1)\n(29406, 43)\n(9803, 43)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# ***Train the model and make predictions***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# minibatcher function gerenates minibatches of training data\n# at each training iteration, a minibatch of samples \n# is inserted into the model \ndef minibatcher(x, y, batch_size, shuffle):\n    assert x.shape[0] == y.shape[0]\n    n_samples = x.shape[0]\n    if shuffle:\n        idx = np.random.permutation (n_samples)\n    else:\n        idx = list(range(n_samples))\n    for k in range (int(np.ceil(n_samples/batch_size))):\n        from_idx = k*batch_size\n        to_idx = (k+1)*batch_size\n        yield x[idx[from_idx:to_idx],...], y[idx[from_idx:to_idx],...] \n\nbatch_size = 10000\nfor mb in minibatcher(Xtrain, ytrain, batch_size, True):\n    print(mb[0].shape, mb[1].shape)\n        \n    \n    ","execution_count":36,"outputs":[{"output_type":"stream","text":"(10000, 32, 32, 1) (10000, 43)\n(10000, 32, 32, 1) (10000, 43)\n(9406, 32, 32, 1) (9406, 43)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build the blocks that will compose the network\n\nimport tensorflow as tf\n\n# fc_no_activation_layer represents a fully \n# connected layer without an activation function\n# with 'w' denotes the weights and 'b' the bias\n\ndef fc_no_activation_layer(in_tensors, n_units):\n    with tf1.variable_scope('fc_layer', reuse = tf1.AUTO_REUSE):\n        w = tf1.get_variable('fc_W', [in_tensors.get_shape()[1], n_units],\n                        tf.float32, tf.keras.initializers.GlorotUniform())\n        b = tf1.get_variable('fc_B', [n_units,], tf.float32,\n                        tf.constant_initializer(0.0))\n    return tf.matmul(in_tensors, w) + b\n\n# A fully connected layer with leaky ReLU\n# as an activation function\ndef fc_layer(in_tensors, n_units):\n    return tf.nn.leaky_relu(fc_no_activation_layer(in_tensors, n_units))\n\n# A convolutional layer with the activation\n# function leaky ReLU\ndef conv_layer(in_tensors, kernel_size, n_units):\n    with tf1.variable_scope('c_layer', reuse = tf1.AUTO_REUSE):\n        w = tf1.get_variable('conv_W', [kernel_size, kernel_size, in_tensors.get_shape()[3], n_units],\n                        tf.float32, tf.keras.initializers.GlorotUniform())\n        b = tf1.get_variable('conv_B', [n_units,], tf.float32,\n                        tf.constant_initializer(0.0))\n    return tf.nn.leaky_relu(tf.nn.conv2d(in_tensors, w , [1, 1, 1, 1], 'SAME') + b)\n\n# A Maxpooling layer\ndef maxpool_layer(in_tensors, sampling):\n    return tf.nn.max_pool(in_tensors, [1, sampling, sampling, 1], [1, sampling, sampling, 1], 'SAME')\n\n# A dropout layer for regularizing the network\ndef dropout(in_tensors, keep_prob, is_training):\n    return tf.cond(is_training, lambda: tf.nn.dropout(in_tensors, keep_prob), lambda: in_tensors)\n\n    ","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model\ndef model(in_tensors, is_training):\n    # First layer: 5x5 2d-conv, 32 filters, 2x maxpool, 20% dropout\n    with tf1.variable_scope('l1_scope', reuse=tf1.AUTO_REUSE):\n        l1 = maxpool_layer(conv_layer(in_tensors, 5, 32), 2)\n        l1_out = dropout(l1, 0.8, is_training)\n        # Second layer: 5x5 2d-conv, 64 filters, 2x maxpool, 20% dropout\n    with tf1.variable_scope('l2_scope', reuse=tf1.AUTO_REUSE):\n        l2 = maxpool_layer(conv_layer(l1_out, 5, 64), 2)\n        l2_out = dropout(l2, 0.8, is_training)\n    with tf1.variable_scope('flatten', reuse=tf1.AUTO_REUSE):\n        l2_out_flat = tf1.layers.flatten(l2_out)\n    # Fully connected layer, 1024 neurons, 40% dropout\n    with tf1.variable_scope('l3_scope', reuse=tf1.AUTO_REUSE):\n        l3 = fc_layer(l2_out_flat, 1024)\n        l3_out = dropout(l3, 0.6, is_training)\n    # Output\n    with tf1.variable_scope('out', reuse=tf1.AUTO_REUSE):\n        out_tensors = fc_no_activation_layer(l3_out, n_classes)\n    return out_tensors\n    \n        ","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\n# Train the model on the training set\n# and test the performance on the test set\ndef train_model(X_train, y_train, X_test, y_test, batch_size, learning_rate, max_epochs):\n    \n    # Define 3 Tensorfow placeholders;\n    # one for the minibatch of images\n    # one for the minibatch of labels\n    # and the last one to select whether to run for training or not\n    in_X_tensors_batch = tf1.placeholder(tf.float32, shape = (None,resized_image[0], resized_image[1], 1 ))\n    in_y_tensors_batch = tf1.placeholder(tf.float32, shape = (None,n_classes))\n    is_training = tf1.placeholder(tf.bool)\n    \n    #Define the output, metric score, and optimizer   \n    logits = model(in_X_tensors_batch, is_training)\n    out_y_pred = tf.nn.softmax(logits)\n    loss_score = tf1.nn.softmax_cross_entropy_with_logits(logits=logits, labels=in_y_tensors_batch)\n    loss = tf.reduce_mean(loss_score)\n    optimizer = tf1.train.AdamOptimizer(learning_rate).minimize(loss)\n    \n    # Train the model with minibatches\n    with tf1.Session() as session:\n        session.run(tf1.global_variables_initializer())\n        for epoch in range(max_epochs):\n            print('Epochs=', epoch)\n            tf_score = []\n            for mb in minibatcher(X_train, y_train, batch_size, shuffle = True):\n                tf_output = session.run([optimizer, loss], feed_dict = {in_X_tensors_batch : mb[0],\n                                                                        in_y_tensors_batch : mb[1], \n                                                                        is_training : True})\n                tf_score.append(tf_output[1])\n            print('train_loss_score=', np.mean(tf_score))\n        \n        #Test the model on the test set\n        # Test on the whole test set\n        print('TEST SET PERFORMANCE')\n        y_test_pred, test_loss = session.run([out_y_pred, loss],\n                                            feed_dict = {in_X_tensors_batch:X_test, \n                                                        in_y_tensors_batch:y_test, \n                                                         is_training:False})\n        \n        # Print the classification report\n        print(' test_loss_score=', test_loss)\n        y_test_pred_classified = np.argmax(y_test_pred, axis=1).astype(np.int32)\n        y_test_true_classified = np.argmax(y_test, axis=1).astype(np.int32)\n        print(classification_report(y_test_true_classified, y_test_pred_classified))\n       \n    tf1.reset_default_graph()\n   ","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Run the model with a learning step of 0.001,\n#256 samples per minibatch,\n#and 10 epochs\ntrain_model(Xtrain,ytrain, Xtest, ytest, 256, 0.001, 10)","execution_count":40,"outputs":[{"output_type":"stream","text":"Epochs= 0\ntrain_loss_score= 10.573887\nEpochs= 1\ntrain_loss_score= 3.7204692\nEpochs= 2\ntrain_loss_score= 2.8357174\nEpochs= 3\ntrain_loss_score= 2.256787\nEpochs= 4\ntrain_loss_score= 1.8650717\nEpochs= 5\ntrain_loss_score= 1.597425\nEpochs= 6\ntrain_loss_score= 1.406965\nEpochs= 7\ntrain_loss_score= 1.2480186\nEpochs= 8\ntrain_loss_score= 1.1402963\nEpochs= 9\ntrain_loss_score= 1.0530018\nTEST SET PERFORMANCE\n test_loss_score= 0.37848884\n              precision    recall  f1-score   support\n\n           0       1.00      0.60      0.75        60\n           1       0.94      0.71      0.81       547\n           2       0.70      0.92      0.79       557\n           3       0.88      0.82      0.85       345\n           4       0.94      0.91      0.92       508\n           5       0.74      0.74      0.74       444\n           6       0.75      0.98      0.85       106\n           7       0.94      0.79      0.86       384\n           8       0.71      0.95      0.82       330\n           9       0.99      0.93      0.96       362\n          10       0.91      0.97      0.94       498\n          11       1.00      0.89      0.94       343\n          12       0.89      0.98      0.93       502\n          13       0.99      0.98      0.98       574\n          14       0.98      0.99      0.98       163\n          15       0.91      0.98      0.94       149\n          16       0.98      0.96      0.97       106\n          17       0.99      0.98      0.98       277\n          18       0.92      0.99      0.96       297\n          19       0.91      0.75      0.82        53\n          20       0.53      0.94      0.68        94\n          21       0.87      0.76      0.81        79\n          22       0.98      0.97      0.98       109\n          23       0.98      0.60      0.75       144\n          24       0.98      0.71      0.82        66\n          25       0.97      0.94      0.96       407\n          26       0.93      0.87      0.90       145\n          27       0.70      0.97      0.82        64\n          28       0.90      0.91      0.90       132\n          29       0.88      0.81      0.84        70\n          30       0.91      0.83      0.87        95\n          31       0.90      0.96      0.93       193\n          32       1.00      0.51      0.67        59\n          33       0.94      0.94      0.94       163\n          34       0.92      0.96      0.94        99\n          35       1.00      0.95      0.97       281\n          36       0.96      0.98      0.97        94\n          37       0.98      0.98      0.98        44\n          38       0.98      0.96      0.97       556\n          39       1.00      0.89      0.94        85\n          40       0.86      0.76      0.81        96\n          41       1.00      0.92      0.96        62\n          42       1.00      0.84      0.91        61\n\n    accuracy                           0.90      9803\n   macro avg       0.91      0.88      0.89      9803\nweighted avg       0.91      0.90      0.90      9803\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}